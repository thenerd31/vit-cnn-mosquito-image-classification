{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06635526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration TheNoob3131--mosquito-data-bf1f4d4d5f427763\n",
      "Reusing dataset csv (C:\\Users\\Aswin.Surya24\\.cache\\huggingface\\datasets\\TheNoob3131___csv\\TheNoob3131--mosquito-data-bf1f4d4d5f427763\\0.0.0\\51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778ff5de15c947e0bf69b20dfb4ecf29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('TheNoob3131/mosquito-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f61449",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].features['Photo']\n",
    "from datasets import Image\n",
    "dataset = dataset.cast_column('Photo', Image(decode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b364dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function Dataset.class_encode_column.<locals>.cast_to_class_labels at 0x00000210D3C24160> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac19b27441c14b6bad772aaa2614baf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69675700f34f438d91a2041750b8fa06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebfcb6fc2064cbc92da726fbe3b9629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a25618766c46faa1460b7a42c9ecd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.class_encode_column('Classification')\n",
    "dataset = dataset.rename_column('Classification', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb5de06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aedes', 'culex', 'neither']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d01b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'aedes', 1: 'culex', 2: 'neither'}\n"
     ]
    }
   ],
   "source": [
    "id2label = {k:v for k,v in enumerate(labels)}\n",
    "label2id = {v:k for k,v in enumerate(labels)}\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66209a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNextFeatureExtractor {\n",
      "  \"crop_pct\": 0.875,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"feature_extractor_type\": \"ConvNextFeatureExtractor\",\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"size\": 224\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import ConvNextFeatureExtractor\n",
    "model_name_or_path = 'facebook/convnext-base-224-22k'\n",
    "feature_extractor = ConvNextFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "print(feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4947e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "     RandomResizedCrop(feature_extractor.size),\n",
    "     RandomHorizontalFlip(),\n",
    "     ToTensor(),\n",
    "     normalize\n",
    "    ]\n",
    ")\n",
    "\n",
    "def train_transforms(examples):\n",
    "  examples[\"pixel_values\"] = [transform(image.convert(\"RGB\")) for image in examples[\"Photo\"]]\n",
    "\n",
    "  return examples\n",
    "\n",
    "#def transform(example_batch):\n",
    "    # Take a list of PIL images and turn them to pixel values\n",
    "  #  inputs = feature_extractor([x for x in example_batch['Photo']], return_tensors='pt')\n",
    "\n",
    "    # Don't forget to include the labels!\n",
    "  #  inputs['labels'] = example_batch['labels']\n",
    "  #  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff805c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_ds = dataset.with_transform(train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0243173d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_ds[\"train\"][0][\"pixel_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "683c49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "def collate_fn(examples):\n",
    "  pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "  labels = torch.tensor([example[\"labels\"] for example in examples])\n",
    "\n",
    "  return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "dataloader = DataLoader(prepared_ds[\"train\"], collate_fn=collate_fn, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffacf0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values torch.Size([4, 3, 224, 224])\n",
      "labels torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "for k,v in batch.items():\n",
    "  print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41216c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10557f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ConvNextForImageClassification were not initialized from the model checkpoint at facebook/convnext-base-224-22k and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([21841, 1024]) in the checkpoint and torch.Size([3, 1024]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([21841]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvNextForImageClassification(\n",
       "  (convnext): ConvNextModel(\n",
       "    (embeddings): ConvNextEmbeddings(\n",
       "      (patch_embeddings): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (layernorm): ConvNextLayerNorm()\n",
       "    )\n",
       "    (encoder): ConvNextEncoder(\n",
       "      (stages): ModuleList(\n",
       "        (0): ConvNextStage(\n",
       "          (downsampling_layer): Identity()\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextLayer(\n",
       "              (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextLayer(\n",
       "              (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextLayer(\n",
       "              (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ConvNextStage(\n",
       "          (downsampling_layer): Sequential(\n",
       "            (0): ConvNextLayerNorm()\n",
       "            (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextLayer(\n",
       "              (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextLayer(\n",
       "              (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextLayer(\n",
       "              (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ConvNextStage(\n",
       "          (downsampling_layer): Sequential(\n",
       "            (0): ConvNextLayerNorm()\n",
       "            (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (3): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (4): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (5): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (6): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (7): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (8): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (9): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (10): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (11): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (12): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (13): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (14): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (15): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (16): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (17): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (18): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (19): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (20): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (21): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (22): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (23): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (24): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (25): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (26): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ConvNextStage(\n",
       "          (downsampling_layer): Sequential(\n",
       "            (0): ConvNextLayerNorm()\n",
       "            (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextLayer(\n",
       "              (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextLayer(\n",
       "              (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextLayer(\n",
       "              (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ConvNextForImageClassification\n",
    "#print(len(labels))\n",
    "model = ConvNextForImageClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4e5c6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNextForImageClassification(\n",
       "  (convnext): ConvNextModel(\n",
       "    (embeddings): ConvNextEmbeddings(\n",
       "      (patch_embeddings): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (layernorm): ConvNextLayerNorm()\n",
       "    )\n",
       "    (encoder): ConvNextEncoder(\n",
       "      (stages): ModuleList(\n",
       "        (0): ConvNextStage(\n",
       "          (downsampling_layer): Identity()\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextLayer(\n",
       "              (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextLayer(\n",
       "              (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextLayer(\n",
       "              (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ConvNextStage(\n",
       "          (downsampling_layer): Sequential(\n",
       "            (0): ConvNextLayerNorm()\n",
       "            (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextLayer(\n",
       "              (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextLayer(\n",
       "              (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextLayer(\n",
       "              (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ConvNextStage(\n",
       "          (downsampling_layer): Sequential(\n",
       "            (0): ConvNextLayerNorm()\n",
       "            (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (3): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (4): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (5): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (6): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (7): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (8): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (9): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (10): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (11): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (12): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (13): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (14): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (15): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (16): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (17): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (18): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (19): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (20): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (21): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (22): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (23): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (24): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (25): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (26): ConvNextLayer(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ConvNextStage(\n",
       "          (downsampling_layer): Sequential(\n",
       "            (0): ConvNextLayerNorm()\n",
       "            (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextLayer(\n",
       "              (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextLayer(\n",
       "              (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextLayer(\n",
       "              (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "              (layernorm): ConvNextLayerNorm()\n",
       "              (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d90621ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MHM Id': 17233.0,\n",
       " 'labels': 0,\n",
       " 'Container': 'plant clumps (bamboo etc)',\n",
       " 'Userid': 2538037,\n",
       " 'latitude': -22.8854,\n",
       " 'longitude': 47.7708,\n",
       " 'date': '9/19/2019',\n",
       " 'Photo': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=4160x3120 at 0x210D8B79220>,\n",
       " 'pixel_values': tensor([[[-1.9638, -1.9980, -1.9980,  ..., -2.0323, -2.0323, -1.9809],\n",
       "          [-2.0152, -1.9980, -1.9980,  ..., -2.0323, -1.9980, -1.9809],\n",
       "          [-1.9638, -2.0152, -1.9980,  ..., -2.0323, -2.0152, -1.9980],\n",
       "          ...,\n",
       "          [-1.9467, -1.9467, -1.9638,  ..., -2.0323, -2.0323, -2.0837],\n",
       "          [-1.9295, -1.9124, -1.9809,  ..., -2.0323, -2.0494, -2.0837],\n",
       "          [-1.9295, -1.9467, -1.9467,  ..., -2.0323, -2.0323, -2.0323]],\n",
       " \n",
       "         [[-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
       "          [-2.0182, -2.0182, -2.0357,  ..., -2.0182, -2.0357, -2.0357],\n",
       "          [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0357],\n",
       "          ...,\n",
       "          [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
       "          [-2.0182, -2.0007, -2.0182,  ..., -2.0182, -2.0182, -2.0182],\n",
       "          [-2.0182, -2.0182, -2.0182,  ..., -2.0182, -2.0357, -2.0182]],\n",
       " \n",
       "         [[-1.7522, -1.7696, -1.7870,  ..., -1.7696, -1.7696, -1.7870],\n",
       "          [-1.7696, -1.7522, -1.7870,  ..., -1.7696, -1.7696, -1.7870],\n",
       "          [-1.7696, -1.7696, -1.7870,  ..., -1.7696, -1.7696, -1.7870],\n",
       "          ...,\n",
       "          [-1.7347, -1.7347, -1.7522,  ..., -1.7696, -1.7696, -1.7347],\n",
       "          [-1.7347, -1.7173, -1.7522,  ..., -1.7696, -1.7870, -1.7347],\n",
       "          [-1.7696, -1.7347, -1.7347,  ..., -1.7696, -1.7347, -1.7522]]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b429bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metric1 = load_metric(\"precision\")\n",
    "    metric2 = load_metric(\"recall\")\n",
    "    metric3 = load_metric(\"f1\")\n",
    "    metric4 = load_metric(\"accuracy\")\n",
    "  \n",
    "\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision = metric1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"]\n",
    "    recall = metric2.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"]\n",
    "    f1 = metric3.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
    "    accuracy = metric4.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a7769b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./convnext-base-mosquito\",\n",
    "  per_device_train_batch_size=8,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=4,\n",
    "  save_steps=100,\n",
    "  eval_steps=100,\n",
    "  logging_steps=10,\n",
    "  learning_rate=2e-4,\n",
    "  save_total_limit=2,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to='tensorboard',\n",
    "  load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edbbc82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MHM Id': Value(dtype='float64', id=None),\n",
       " 'labels': ClassLabel(num_classes=3, names=['aedes', 'culex', 'neither'], id=None),\n",
       " 'Container': Value(dtype='string', id=None),\n",
       " 'Userid': Value(dtype='int64', id=None),\n",
       " 'latitude': Value(dtype='float64', id=None),\n",
       " 'longitude': Value(dtype='float64', id=None),\n",
       " 'date': Value(dtype='string', id=None),\n",
       " 'Photo': Image(decode=True, id=None)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_ds['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5620c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_ds[\"train\"],\n",
    "    eval_dataset=prepared_ds[\"test\"],\n",
    "    tokenizer=feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "439b9115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aswin.Surya24\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 7107\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3556\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3556' max='3556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3556/3556 33:08:37, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.962400</td>\n",
       "      <td>0.842519</td>\n",
       "      <td>0.359512</td>\n",
       "      <td>0.599593</td>\n",
       "      <td>0.449504</td>\n",
       "      <td>0.599593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.907300</td>\n",
       "      <td>0.838380</td>\n",
       "      <td>0.562151</td>\n",
       "      <td>0.604827</td>\n",
       "      <td>0.564939</td>\n",
       "      <td>0.604827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.757800</td>\n",
       "      <td>0.797866</td>\n",
       "      <td>0.596527</td>\n",
       "      <td>0.628671</td>\n",
       "      <td>0.608520</td>\n",
       "      <td>0.628671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.733900</td>\n",
       "      <td>0.805577</td>\n",
       "      <td>0.612129</td>\n",
       "      <td>0.637976</td>\n",
       "      <td>0.599691</td>\n",
       "      <td>0.637976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.655700</td>\n",
       "      <td>0.957681</td>\n",
       "      <td>0.584131</td>\n",
       "      <td>0.571969</td>\n",
       "      <td>0.568025</td>\n",
       "      <td>0.571969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.684300</td>\n",
       "      <td>0.831955</td>\n",
       "      <td>0.641886</td>\n",
       "      <td>0.631870</td>\n",
       "      <td>0.625072</td>\n",
       "      <td>0.631870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.561800</td>\n",
       "      <td>0.820480</td>\n",
       "      <td>0.644464</td>\n",
       "      <td>0.661820</td>\n",
       "      <td>0.637497</td>\n",
       "      <td>0.661820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.694400</td>\n",
       "      <td>0.767711</td>\n",
       "      <td>0.649529</td>\n",
       "      <td>0.666764</td>\n",
       "      <td>0.636907</td>\n",
       "      <td>0.666764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.751415</td>\n",
       "      <td>0.633549</td>\n",
       "      <td>0.651643</td>\n",
       "      <td>0.632334</td>\n",
       "      <td>0.651643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.746100</td>\n",
       "      <td>0.933204</td>\n",
       "      <td>0.626335</td>\n",
       "      <td>0.566444</td>\n",
       "      <td>0.590080</td>\n",
       "      <td>0.566444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.676900</td>\n",
       "      <td>0.801869</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>0.632742</td>\n",
       "      <td>0.629251</td>\n",
       "      <td>0.632742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.683600</td>\n",
       "      <td>0.909258</td>\n",
       "      <td>0.634653</td>\n",
       "      <td>0.626345</td>\n",
       "      <td>0.609911</td>\n",
       "      <td>0.626345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.424100</td>\n",
       "      <td>0.874704</td>\n",
       "      <td>0.668989</td>\n",
       "      <td>0.651352</td>\n",
       "      <td>0.629185</td>\n",
       "      <td>0.651352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.743000</td>\n",
       "      <td>0.872144</td>\n",
       "      <td>0.657424</td>\n",
       "      <td>0.603664</td>\n",
       "      <td>0.624661</td>\n",
       "      <td>0.603664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.721000</td>\n",
       "      <td>0.776873</td>\n",
       "      <td>0.671591</td>\n",
       "      <td>0.664437</td>\n",
       "      <td>0.655829</td>\n",
       "      <td>0.664437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.753302</td>\n",
       "      <td>0.652053</td>\n",
       "      <td>0.652224</td>\n",
       "      <td>0.652086</td>\n",
       "      <td>0.652224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.525200</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.654508</td>\n",
       "      <td>0.618494</td>\n",
       "      <td>0.629448</td>\n",
       "      <td>0.618494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.538500</td>\n",
       "      <td>0.868440</td>\n",
       "      <td>0.645460</td>\n",
       "      <td>0.600756</td>\n",
       "      <td>0.613940</td>\n",
       "      <td>0.600756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.635600</td>\n",
       "      <td>0.922432</td>\n",
       "      <td>0.689017</td>\n",
       "      <td>0.636522</td>\n",
       "      <td>0.642462</td>\n",
       "      <td>0.636522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.470700</td>\n",
       "      <td>0.889999</td>\n",
       "      <td>0.679813</td>\n",
       "      <td>0.646700</td>\n",
       "      <td>0.654107</td>\n",
       "      <td>0.646700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.622300</td>\n",
       "      <td>0.940239</td>\n",
       "      <td>0.673394</td>\n",
       "      <td>0.614132</td>\n",
       "      <td>0.638538</td>\n",
       "      <td>0.614132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.447100</td>\n",
       "      <td>0.797108</td>\n",
       "      <td>0.665255</td>\n",
       "      <td>0.646700</td>\n",
       "      <td>0.651229</td>\n",
       "      <td>0.646700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.307800</td>\n",
       "      <td>0.847387</td>\n",
       "      <td>0.703871</td>\n",
       "      <td>0.676359</td>\n",
       "      <td>0.661681</td>\n",
       "      <td>0.676359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.430900</td>\n",
       "      <td>0.931386</td>\n",
       "      <td>0.665384</td>\n",
       "      <td>0.626054</td>\n",
       "      <td>0.642646</td>\n",
       "      <td>0.626054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.538200</td>\n",
       "      <td>0.910526</td>\n",
       "      <td>0.678267</td>\n",
       "      <td>0.637685</td>\n",
       "      <td>0.648755</td>\n",
       "      <td>0.637685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.634900</td>\n",
       "      <td>0.951943</td>\n",
       "      <td>0.663794</td>\n",
       "      <td>0.620529</td>\n",
       "      <td>0.635117</td>\n",
       "      <td>0.620529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.324100</td>\n",
       "      <td>0.940193</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.640884</td>\n",
       "      <td>0.649425</td>\n",
       "      <td>0.640884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.304900</td>\n",
       "      <td>0.997845</td>\n",
       "      <td>0.690985</td>\n",
       "      <td>0.671998</td>\n",
       "      <td>0.675625</td>\n",
       "      <td>0.671998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.476500</td>\n",
       "      <td>0.939841</td>\n",
       "      <td>0.671158</td>\n",
       "      <td>0.648154</td>\n",
       "      <td>0.657911</td>\n",
       "      <td>0.648154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.963759</td>\n",
       "      <td>0.685835</td>\n",
       "      <td>0.657749</td>\n",
       "      <td>0.665169</td>\n",
       "      <td>0.657749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.445300</td>\n",
       "      <td>0.944031</td>\n",
       "      <td>0.701231</td>\n",
       "      <td>0.671998</td>\n",
       "      <td>0.679357</td>\n",
       "      <td>0.671998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.265800</td>\n",
       "      <td>0.964911</td>\n",
       "      <td>0.678271</td>\n",
       "      <td>0.664147</td>\n",
       "      <td>0.664318</td>\n",
       "      <td>0.664147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.425900</td>\n",
       "      <td>0.965507</td>\n",
       "      <td>0.689515</td>\n",
       "      <td>0.666473</td>\n",
       "      <td>0.671211</td>\n",
       "      <td>0.666473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>1.008616</td>\n",
       "      <td>0.689473</td>\n",
       "      <td>0.661530</td>\n",
       "      <td>0.667372</td>\n",
       "      <td>0.661530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.394700</td>\n",
       "      <td>1.008213</td>\n",
       "      <td>0.683096</td>\n",
       "      <td>0.657749</td>\n",
       "      <td>0.665653</td>\n",
       "      <td>0.657749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "C:\\Users\\Aswin.Surya24\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-100\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-100\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-100\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-100\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "C:\\Users\\Aswin.Surya24\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-200\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-200\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-200\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-200\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "C:\\Users\\Aswin.Surya24\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-300\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-300\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-300\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-300\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-400\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-400\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-400\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-400\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-500\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-500\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-500\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-500\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-600\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-600\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-600\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-600\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-700\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-700\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-700\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-700\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-800\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-800\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-800\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-800\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-900\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-900\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-900\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-900\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-1000\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-1000\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-1000\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-1100\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-1100\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-1100\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-1200\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-1200\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-1200\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-1100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-1300\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-1300\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-1300\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-1200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-1400\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-1400\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-1400\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-1300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-1500\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-1500\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-1500\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-1400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-1600\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-1600\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-1600\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-1700\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-1700\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-1700\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-1600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-1800\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-1800\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-1800\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-1700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-1900\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-1900\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-1900\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-1800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-2000\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-2000\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-2000\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-1900] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-2100\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-2100\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-2100\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-2000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-2200\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-2200\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-2200\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-2100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-2300\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-2300\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-2300\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-2200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-2400\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-2400\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-2400\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-2300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-2500\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-2500\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-2500\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-2400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-2600\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-2600\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-2600\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-2600\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-2500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-2700\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-2700\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-2700\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-2700\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-2600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-2800\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-2800\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-2800\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-2800\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-2700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-2900\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-2900\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-2900\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-2900\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-2800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-3000\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-3000\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-3000\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-3000\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-2900] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-3100\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-3100\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-3100\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-3100\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-3000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-3200\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-3200\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-3200\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-3200\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-3100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-3300\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-3300\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-3300\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-3300\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-3200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-3400\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-3400\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-3400\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-3400\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-3300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./convnext-base-mosquito\\checkpoint-3500\n",
      "Configuration saved in ./convnext-base-mosquito\\checkpoint-3500\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\checkpoint-3500\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\checkpoint-3500\\preprocessor_config.json\n",
      "Deleting older checkpoint [convnext-base-mosquito\\checkpoint-3400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./convnext-base-mosquito\\checkpoint-900 (score: 0.7514153122901917).\n",
      "Saving model checkpoint to ./convnext-base-mosquito\n",
      "Configuration saved in ./convnext-base-mosquito\\config.json\n",
      "Model weights saved in ./convnext-base-mosquito\\pytorch_model.bin\n",
      "Feature extractor saved in ./convnext-base-mosquito\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =               4.0\n",
      "  total_flos               =      2093958364GF\n",
      "  train_loss               =            0.5627\n",
      "  train_runtime            = 1 day, 9:08:48.33\n",
      "  train_samples_per_second =             0.238\n",
      "  train_steps_per_second   =              0.03\n"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a3af024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='430' max='430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [430/430 37:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        4.0\n",
      "  eval_accuracy           =     0.6563\n",
      "  eval_f1                 =     0.6355\n",
      "  eval_loss               =     0.7498\n",
      "  eval_precision          =     0.6386\n",
      "  eval_recall             =     0.6563\n",
      "  eval_runtime            = 0:37:35.67\n",
      "  eval_samples_per_second =      1.525\n",
      "  eval_steps_per_second   =      0.191\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(prepared_ds['test'])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosquito-project",
   "language": "python",
   "name": "mosquito-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
